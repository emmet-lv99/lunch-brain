'use server'

import { getEmbedding } from '@/lib/gemini';
import { supabase } from '@/lib/supabase';
import { GoogleGenerativeAI } from "@google/generative-ai";

const genAI = new GoogleGenerativeAI(process.env.GOOGLE_GEMINI_API_KEY!);

export async function askChatbot(message: string) {
  try {
    // ğŸ¯ ì—¬ê¸°ì„œ ì—ëŸ¬ê°€ ë‚¬ë˜ ê²ë‹ˆë‹¤. ì´ì œ ìˆ˜ë¦¬ëœ getEmbeddingì´ ì‘ë™í•©ë‹ˆë‹¤.
    const queryVector = await getEmbedding(message);

    // 3072ì°¨ì›ìœ¼ë¡œ ìˆ˜ì •ëœ RPC í˜¸ì¶œ
    const { data: matchedRestaurants, error: matchError } = await supabase.rpc('match_restaurants', {
      query_embedding: queryVector,
      match_threshold: 0.2, // í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì¡°ê¸ˆ ë‚®ì¶°ë´…ë‹ˆë‹¤.
      match_count: 5
    });

    if (matchError) throw matchError;

    // 3. ê²€ìƒ‰ëœ ì‹ë‹¹ ì •ë³´ë¥¼ í…ìŠ¤íŠ¸ë¡œ ì •ë¦¬
    const context = matchedRestaurants
      .map((r: any) => `- ${r.name} (${r.category_main}): ${r.category_sub}`)
      .join('\n');

    // 4. Geminiì—ê²Œ ë‹µë³€ ìƒì„± ìš”ì²­ (í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§)
    const model = genAI.getGenerativeModel({ model: "gemini-2.0-flash" });
    const prompt = `
      ë„ˆëŠ” ë§›ì§‘ ì¶”ì²œ ì „ë¬¸ê°€ 'ëŸ°ì¹˜ ë¸Œë ˆì¸ ğŸ¯'ì´ì•¼. 
      ì•„ë˜ ì œê³µëœ ì‹ë‹¹ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê³  ìœ„íŠ¸ìˆê²Œ ëŒ€ë‹µí•´ì¤˜.
      ì‹ë‹¹ ì •ë³´ê°€ ì—†ë‹¤ë©´ ì•„ëŠ” ì²™ í•˜ì§€ ë§ê³  ì •ì¤‘í•˜ê²Œ ëª¨ë¥¸ë‹¤ê³  í•´.

      [ê²€ìƒ‰ëœ ì‹ë‹¹ ì •ë³´]
      ${context}

      [ì‚¬ìš©ì ì§ˆë¬¸]
      ${message}
    `;

    const result = await model.generateContent(prompt);
    return { success: true, answer: result.response.text() };
  } catch (error: any) {
    console.error("âŒ ì±—ë´‡ ì˜¤ë¥˜:", error.message);
    return { success: false, error: "í˜¸ë‘ì´ê°€ ì ì‹œ ìë¦¬ë¥¼ ë¹„ì› ìŠµë‹ˆë‹¤." };
  }
}